\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}

\section*{History \& context}
\addcontentsline{toc}{section}{History \& context}
According to the annals of history, the term \textit{computational neuroscience} was coined by Eric L. Schwartz in 1985 when he organized a conference\footnote{\citep{schwartz1990computational}} to provide a summary of the current status of a field at that time known under a variety of names such as neural modeling, brain theory, and neural networks. The central idea of computational neuroscience, to study the brain through mathematical models, is much older than that, however. First modern traces can be found as early as in 1907 when Louis Lapicque introduced\footnote{\citep{Lapicque1907}} the integrate and fire model. While crude, the model managed to describe observed interactions of a nerve fiber long before the exact mechanisms responsible for generation of neuron action potentials were discovered. Doing so, it greatly contributed to our understanding of the brain and laid a strong foundation for further research.

One of the main approaches in computational neuroscience goes under the name \textit{system identification}: first, through experimentation one obtains a large dataset of input and output pairs of a given neural system - e.g. pairs of images and responses of neurons in primary visual cortex. These are subsequently fitted through machine learning methods with a model, in the hope of identifying the computations that the neural system does to translate the inputs to its outputs. 

Such methods effectively enable us to predict the response of a system to an arbitrary plausible input. Doing so is one of the best ways to test our understanding of such a system. While having a model that predicts the response accurately does not necessarily have to mean our understanding of the biological fundamentals is correct, it is a clear signal it is at least plausible. On the other hand, the opposite, when a model based on our knowledge is not accurate, is proof we should revisit our assumptions. Such an approach is particularly effective in early stages of sensory systems whose primary function is to produce a response encoding to a clearly defined input - sensory stimulus. 

Unsurprisingly, going as far back as to the 1960s, visual neuroscience has been close to traditional image processing and has used its toolkit for computational modeling. The influence was not one-sided. Several ideas, such as convolution layers, inspired by biological observations\footnote{\citep{Lindsay_2020}} have found their way back to classical computer vision. In recent years, the combination of advancements in deep learning vision and higher volume of better data in visual neuroscience, have caused increased focus on deep learning inspired neural models. 

Deep learning inspired models are only a rough approximation of biological reality, not only at the level of single neuron biophysics but also in terms of overall network architecture. For example, deep neural network (DNN) architectures typically do not model interactions between neurons within a single layer or do not account for direct nonlinear interactions between neurons, such as those provided by neuromodulation or attentional mechanisms in the biological brain. 

\section*{Motivation}
\addcontentsline{toc}{section}{Motivation}
Regardless, classic DNNs are still immensely useful. Through the ability to fit their many parameters to real data, and access to ever increasing toolkit of high performance methods borrowed from classical machine learning, they allow for effective means of approximating the stimulus-response function in many neural subsystems. And thanks to their abstraction level, rapid experimentation of higher level concepts is also easier. Much like the integrate and fire model that also abstracted over certain details, they can still inform our understanding of the nature of vision processing. 

However, despite the success of DNNs in neuroscience, having outclassed classical system identification methods in most domains, there remains a substantial gap between the predictions these models give and the actual measured neural responses. This is true even in the most peripheral stages of visual processing such as primary visual cortex. Furthermore, the poor interpretability of the DNN models has been identified as a major challenge limiting their usefulness for understanding neural computation.

To address these issues, a recent model by \cite{antolik}, which will be the focus of the present thesis, explored the idea of incorporating more biologically plausible components into the DNN framework. It showed that such an approach leads to a model with fewer parameters, better interpretability, and outperformed, at the time of writing, other state-of-the-art approaches. 

However, the \citeauthor{antolik} \citeyear{antolik} study also showed shortcomings. The model was very sensitive to random initialization, most hyper-parameters of the model were not thoroughly studied, and more direct one-to-one comparison of the biologically inspired versus classical DNN components was missing. Furthermore, since its publishing, several studies using classical DNN techniques managed to demonstrate slight improvement over the \citeauthor{antolik} data. Finally, the model has been implemented in an ad-hoc way in now discontinued ML framework Theano, which poses a problem for further exploration of the bio-inspired DNNs architecture idea.

\section*{Motivation}
\addcontentsline{toc}{section}{Motivation}
The goal of this thesis is to address the outlined outstanding issues with the \citeauthor{antolik} study, in order to provide a stable, fine-tuned, and well characterized implementation in a modern neuroscience oriented DNN framework to enable future experimentation with this bio-inspired architecture. Following contributions are the goals of this thesis:

\begin{itemize}
    \item \textbf{Assess the \citeauthor{antolik} model (and its variants) in terms of stability and sensitivity to hyperparameter finetuning:} Especially on low quantities of noisy data, which is common in the field of sensory neuroscience, models tend to be relatively unstable with respect to both hyperparameters fine-tuning but also random initialization. We want to quantify the effects and hopefully explore ways to mitigate them to ensure any conclusions drawn are not due to a chance but rather architectural properties. As part of this, we will make use of our whole dataset, comparing various architectures across its three separate subsets.
    \item \textbf{Evaluate novel architectures inspired by classical computer vision:} We want to compare the benefits of biologically restricted techniques with more computationally generic approaches from classical deep computer vision and investigate whether hard constraints could be replaced with well chosen regularization schemes. Furthermore, test the impact of several deep learning techniques that were shown to work on classical computer vision problems.
    \item \textbf{Improve upon \citeauthor{antolik} model:} Decrease the gap between the original model and more recent less biologically constrained architectures that demonstrated improved performance. 
    \item \textbf{Contribute new functionality to the NDN3 library toolbox:} We contribute all tools developed to conduct experiments in this thesis upstream to the NDN3 framework or, where not applicable, publish them separately under open source license. The goal is to enable others to iterate on our findings and evaluate the results in a shared environment.
    \item \textbf{(Re)implement and assess the \citeauthor{antolik} model and several of its variants within the NDN3 framework:} Similar to the previous point, implementing and analysing various models within a shared framework aims to enable rapid prototyping, and generally facilitate further research.
    \item \textbf{Identify opportunities for further research:} Since our set of goals is relatively broad, we will not be able to dive deep into every encountered question. As a result, we want to identify opportunities for more focused further research.
\end{itemize}

This way, the present thesis represents a stepping stone that will accelerate the future long-term research program on bio-inspired DNN architectures for neuroscientific data underway in the \citeauthor{antolik} group.

\section*{Thesis structure}
\addcontentsline{toc}{section}{Thesis structure}
This thesis is divided into 4 parts. First, in \hyperref[ch:1]{chapter 1} we provide the theoretical background. We start with a high level overview of the initial part of the visual processing system. Then, we introduce both computational neuroscience generally and the tools it uses for system identification tasks, as well as provide a brief summary of the deep learning techniques that will be relevant for our experiments. In \hyperref[ch:2]{chapter 2}, we introduce the \citeauthor{antolik} model and other especially relevant work in more detail. Second, in chapters \hyperref[ch:3]{chapter 3} we describe the implementation of the additional methods necessary to realize our architectures and the experiments pipeline. Then, in \hyperref[ch:4]{chapter 4}, we introduce our methodology for both the model exploration and results analysis, and finish with a training regime overview.

\hyperref[ch:5]{Chapter 5} with experiments and their results follows. We start by reimplementing the \citeauthor{antolik} model. In the first section, we analyse it in terms of stability and sensitivity to training hyperparameters, attempting to get the best and most stable version possible. Then we test regularization on the fully connected layers, impact of additional non-linearity, and input scaling. In the second section, we move towards larger architectural changes, testing elements from other state of the art models, traditional deep computer vision, but also drawing inspiration from simpler tools of computational neuroscience. We conduct a comparison between various computationally similar architectures differing only by the explicitness of imposed regularization. In the third section we explored the effects of transfer learning, by training one instance of a model on all of the datasetâ€™s three separate subsets pooled together. Further, we train the best variants of architectures from previous sections and compare their results to assess the universality of their improvements.

Finally, the last \hyperref[ch:6]{chapter} offers a summary of our findings, provides lessons learned, and suggests ample opportunities for further research.